{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "preliminary-license",
   "metadata": {},
   "source": [
    "# Semantic Features\n",
    "I'm going to try adding semantic features: \n",
    "- vector representations of words\n",
    "- vector representations of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-batman",
   "metadata": {},
   "source": [
    "First thing to try is glove embeddings for words. We'll compare to the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "owned-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import hyper.eval as evl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-domain",
   "metadata": {},
   "source": [
    "Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "legendary-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed.csv\", sep=\"\\t\", dtype={\"content\": \"string\", \"label\": bool})\n",
    "X = data[\"content\"]\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-aggregate",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "indirect-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipe = make_pipeline(\n",
    "    CountVectorizer(), \n",
    "    LogisticRegression(max_iter=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "partial-belarus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.5s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.05309916, 2.48872709, 2.27170467, 2.42785668, 2.40229273]),\n",
       " 'score_time': array([0.06390119, 0.04425859, 0.08256388, 0.04086161, 0.04082966]),\n",
       " 'test_accuracy': array([0.72093023, 0.70542636, 0.70542636, 0.80620155, 0.72093023]),\n",
       " 'test_precision': array([0.63043478, 0.63888889, 0.63888889, 0.78947368, 0.66666667]),\n",
       " 'test_recall': array([0.60416667, 0.47916667, 0.47916667, 0.63829787, 0.46808511]),\n",
       " 'test_f1': array([0.61702128, 0.54761905, 0.54761905, 0.70588235, 0.55      ])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = evl.evaluate_algorithm(X, y, base_pipe)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "regular-norfolk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7317829457364341"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-excellence",
   "metadata": {},
   "source": [
    "These scores match what is in the baseline notebook. This means we have reproducibility, which is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-maine",
   "metadata": {},
   "source": [
    "## Glove embeddings\n",
    "with zeugma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "excellent-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeugma.embeddings import EmbeddingTransformer\n",
    "glove = EmbeddingTransformer(\"glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "small-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_pipeline = make_pipeline(\n",
    "    glove,\n",
    "    LogisticRegression(max_iter=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "endangered-platform",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.1min remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "res = evl.evaluate_algorithm(X, y, glove_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "august-transparency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.91023254, 1.98548007, 1.78395462, 1.71965981, 1.65102267]),\n",
       " 'score_time': array([0.44476247, 0.4780736 , 0.50054312, 0.32994771, 0.29263854]),\n",
       " 'test_accuracy': array([0.62015504, 0.68992248, 0.65116279, 0.7751938 , 0.74418605]),\n",
       " 'test_precision': array([0.48275862, 0.65384615, 0.56521739, 0.82142857, 0.69444444]),\n",
       " 'test_recall': array([0.29166667, 0.35416667, 0.27083333, 0.4893617 , 0.53191489]),\n",
       " 'test_f1': array([0.36363636, 0.45945946, 0.36619718, 0.61333333, 0.60240964])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "future-blame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.696124031007752"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-cancer",
   "metadata": {},
   "source": [
    "So this is not as good as the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-hardwood",
   "metadata": {},
   "source": [
    "## Building a Transformer using spacy embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ethical-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from hyper.transformers import SpacyTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "urban-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "animated-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_transformer = SpacyTransformer(spacy_model, \"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dying-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = make_pipeline(\n",
    "    spacy_transformer,\n",
    "    LogisticRegression(max_iter=300),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "saving-characteristic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.1min remaining:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "results = evl.evaluate_algorithm(X, y, space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "peaceful-membrane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([61.96490002, 64.77607632, 67.31588554, 75.45301342, 74.95549393]),\n",
       " 'score_time': array([15.12033987, 14.11581182, 13.83320427,  8.49561477,  7.1852808 ]),\n",
       " 'test_accuracy': array([0.74418605, 0.69767442, 0.72093023, 0.82170543, 0.7751938 ]),\n",
       " 'test_precision': array([0.66666667, 0.64516129, 0.65      , 0.81578947, 0.78125   ]),\n",
       " 'test_recall': array([0.625     , 0.41666667, 0.54166667, 0.65957447, 0.53191489]),\n",
       " 'test_f1': array([0.64516129, 0.50632911, 0.59090909, 0.72941176, 0.63291139])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mighty-orchestra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.751937984496124"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-kentucky",
   "metadata": {},
   "source": [
    "A bit better than the baseline and much better than the glove embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-sleeve",
   "metadata": {},
   "source": [
    "## Feature union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hairy-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "personalized-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"union\", FeatureUnion(\n",
    "        transformer_list=[\n",
    "            (\"base_vectorizer\", CountVectorizer()),\n",
    "            (\"spacy_vectorizer\", spacy_transformer),\n",
    "        ],\n",
    "    )),\n",
    "    (\"log_reg\", LogisticRegression(max_iter=300)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "alpha-wells",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.2min remaining:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "results = evl.evaluate_algorithm(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "frank-croatia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.05309916, 2.48872709, 2.27170467, 2.42785668, 2.40229273]),\n",
       " 'score_time': array([0.06390119, 0.04425859, 0.08256388, 0.04086161, 0.04082966]),\n",
       " 'test_accuracy': array([0.72093023, 0.70542636, 0.70542636, 0.80620155, 0.72093023]),\n",
       " 'test_precision': array([0.63043478, 0.63888889, 0.63888889, 0.78947368, 0.66666667]),\n",
       " 'test_recall': array([0.60416667, 0.47916667, 0.47916667, 0.63829787, 0.46808511]),\n",
       " 'test_f1': array([0.61702128, 0.54761905, 0.54761905, 0.70588235, 0.55      ])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "coordinate-dealing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7317829457364341"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-island",
   "metadata": {},
   "source": [
    "This isn't working as intended. This is exactly the same score as with the base classifier. I think it's because the outputs of the two transformers aren't the same shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "changing-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_transformer = FeatureUnion(\n",
    "        transformer_list=[\n",
    "            (\"glove_vectorizer\", glove),\n",
    "            (\"spacy_vectorizer\", spacy_transformer),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "billion-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    union_transformer,\n",
    "    LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ahead-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evl.evaluate_algorithm(X, y, pipeline, verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "future-graduation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([75.09200478, 77.23983812, 75.42570567, 78.75791216, 72.82453895]),\n",
       " 'score_time': array([21.33738518, 18.13628912, 17.34909534,  9.07141471,  8.17491913]),\n",
       " 'test_accuracy': array([0.72868217, 0.70542636, 0.68992248, 0.82945736, 0.78294574]),\n",
       " 'test_precision': array([0.65116279, 0.67857143, 0.6       , 0.85714286, 0.77142857]),\n",
       " 'test_recall': array([0.58333333, 0.39583333, 0.5       , 0.63829787, 0.57446809]),\n",
       " 'test_f1': array([0.61538462, 0.5       , 0.54545455, 0.73170732, 0.65853659])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "crazy-stupid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7472868217054264"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-designer",
   "metadata": {},
   "source": [
    "Which is slightly worse than when using only the spacy vectorizer. So the glove vector isn't really doing anything for me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-limitation",
   "metadata": {},
   "source": [
    "## Flair transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "spoken-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, DocumentPoolEmbeddings\n",
    "from flair.data import Sentence\n",
    "from hyper.transformers import FlairTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caring-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = WordEmbeddings(\"glove\")\n",
    "document_embeddings = DocumentPoolEmbeddings([glove_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "running-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_transformer = trans.FlairTransformer(document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "public-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    f_transformer, \n",
    "    LogisticRegression(max_iter=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "colonial-serial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   37.1s remaining:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   41.9s finished\n"
     ]
    }
   ],
   "source": [
    "results = evl.evaluate_algorithm(X, y, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "understood-remark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7348837209302326"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-reflection",
   "metadata": {},
   "source": [
    "So compared to the other glove embeddings, these are much better. But they're not quite as good as the spacy embeddings. They're much faster than the spacy embeddings though. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
