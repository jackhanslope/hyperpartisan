{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "polish-impossible",
   "metadata": {},
   "source": [
    "# Semantic Features\n",
    "I'm going to try adding semantic features: \n",
    "- vector representations of words\n",
    "- vector representations of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-petite",
   "metadata": {},
   "source": [
    "First thing to try is glove embeddings for words. We'll compare to the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "coordinated-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import hyper.eval as evl\n",
    "from hyper.transformers import FlairTransformer, SpacyTransformer\n",
    "from flair.embeddings import TransformerDocumentEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-duplicate",
   "metadata": {},
   "source": [
    "Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tamil-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed.csv\", sep=\"\\t\", dtype={\"content\": \"string\", \"label\": bool})\n",
    "X = data[\"content\"]\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-airline",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "worse-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipe = make_pipeline(\n",
    "    CountVectorizer(), \n",
    "    LogisticRegression(max_iter=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "vietnamese-chess",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.5s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.05309916, 2.48872709, 2.27170467, 2.42785668, 2.40229273]),\n",
       " 'score_time': array([0.06390119, 0.04425859, 0.08256388, 0.04086161, 0.04082966]),\n",
       " 'test_accuracy': array([0.72093023, 0.70542636, 0.70542636, 0.80620155, 0.72093023]),\n",
       " 'test_precision': array([0.63043478, 0.63888889, 0.63888889, 0.78947368, 0.66666667]),\n",
       " 'test_recall': array([0.60416667, 0.47916667, 0.47916667, 0.63829787, 0.46808511]),\n",
       " 'test_f1': array([0.61702128, 0.54761905, 0.54761905, 0.70588235, 0.55      ])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = evl.evaluate_algorithm(X, y, base_pipe)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "occupied-biology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7317829457364341"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-malpractice",
   "metadata": {},
   "source": [
    "These scores match what is in the baseline notebook. This means we have reproducibility, which is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-utility",
   "metadata": {},
   "source": [
    "## Glove embeddings\n",
    "with zeugma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adolescent-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeugma.embeddings import EmbeddingTransformer\n",
    "glove = EmbeddingTransformer(\"glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "intelligent-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_pipeline = make_pipeline(\n",
    "    glove,\n",
    "    LogisticRegression(max_iter=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "plain-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.1min remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "res = evl.evaluate_algorithm(X, y, glove_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "tender-guess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.91023254, 1.98548007, 1.78395462, 1.71965981, 1.65102267]),\n",
       " 'score_time': array([0.44476247, 0.4780736 , 0.50054312, 0.32994771, 0.29263854]),\n",
       " 'test_accuracy': array([0.62015504, 0.68992248, 0.65116279, 0.7751938 , 0.74418605]),\n",
       " 'test_precision': array([0.48275862, 0.65384615, 0.56521739, 0.82142857, 0.69444444]),\n",
       " 'test_recall': array([0.29166667, 0.35416667, 0.27083333, 0.4893617 , 0.53191489]),\n",
       " 'test_f1': array([0.36363636, 0.45945946, 0.36619718, 0.61333333, 0.60240964])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "appropriate-initial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.696124031007752"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-intent",
   "metadata": {},
   "source": [
    "So this is not as good as the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-plant",
   "metadata": {},
   "source": [
    "## Building a Transformer using spacy embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "favorite-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from hyper.transformers import SpacyTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "becoming-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "metallic-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_transformer = SpacyTransformer(spacy_model, \"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pleased-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = make_pipeline(\n",
    "    spacy_transformer,\n",
    "    LogisticRegression(max_iter=300),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "computational-business",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.1min remaining:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "results = evl.evaluate_algorithm(X, y, space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "shaped-cocktail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([61.96490002, 64.77607632, 67.31588554, 75.45301342, 74.95549393]),\n",
       " 'score_time': array([15.12033987, 14.11581182, 13.83320427,  8.49561477,  7.1852808 ]),\n",
       " 'test_accuracy': array([0.74418605, 0.69767442, 0.72093023, 0.82170543, 0.7751938 ]),\n",
       " 'test_precision': array([0.66666667, 0.64516129, 0.65      , 0.81578947, 0.78125   ]),\n",
       " 'test_recall': array([0.625     , 0.41666667, 0.54166667, 0.65957447, 0.53191489]),\n",
       " 'test_f1': array([0.64516129, 0.50632911, 0.59090909, 0.72941176, 0.63291139])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incorrect-tension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.751937984496124"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-redhead",
   "metadata": {},
   "source": [
    "A bit better than the baseline and much better than the glove embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-bulgaria",
   "metadata": {},
   "source": [
    "## Feature union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fitting-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "arbitrary-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"union\", FeatureUnion(\n",
    "        transformer_list=[\n",
    "            (\"base_vectorizer\", CountVectorizer()),\n",
    "            (\"spacy_vectorizer\", spacy_transformer),\n",
    "        ],\n",
    "    )),\n",
    "    (\"log_reg\", LogisticRegression(max_iter=300)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "interim-marketplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.2min remaining:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "results = evl.evaluate_algorithm(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fleet-chick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.05309916, 2.48872709, 2.27170467, 2.42785668, 2.40229273]),\n",
       " 'score_time': array([0.06390119, 0.04425859, 0.08256388, 0.04086161, 0.04082966]),\n",
       " 'test_accuracy': array([0.72093023, 0.70542636, 0.70542636, 0.80620155, 0.72093023]),\n",
       " 'test_precision': array([0.63043478, 0.63888889, 0.63888889, 0.78947368, 0.66666667]),\n",
       " 'test_recall': array([0.60416667, 0.47916667, 0.47916667, 0.63829787, 0.46808511]),\n",
       " 'test_f1': array([0.61702128, 0.54761905, 0.54761905, 0.70588235, 0.55      ])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "micro-pressure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7317829457364341"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-continent",
   "metadata": {},
   "source": [
    "This isn't working as intended. This is exactly the same score as with the base classifier. I think it's because the outputs of the two transformers aren't the same shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "convenient-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_transformer = FeatureUnion(\n",
    "        transformer_list=[\n",
    "            (\"glove_vectorizer\", glove),\n",
    "            (\"spacy_vectorizer\", spacy_transformer),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "social-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    union_transformer,\n",
    "    LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "large-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evl.evaluate_algorithm(X, y, pipeline, verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "historic-skirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([75.09200478, 77.23983812, 75.42570567, 78.75791216, 72.82453895]),\n",
       " 'score_time': array([21.33738518, 18.13628912, 17.34909534,  9.07141471,  8.17491913]),\n",
       " 'test_accuracy': array([0.72868217, 0.70542636, 0.68992248, 0.82945736, 0.78294574]),\n",
       " 'test_precision': array([0.65116279, 0.67857143, 0.6       , 0.85714286, 0.77142857]),\n",
       " 'test_recall': array([0.58333333, 0.39583333, 0.5       , 0.63829787, 0.57446809]),\n",
       " 'test_f1': array([0.61538462, 0.5       , 0.54545455, 0.73170732, 0.65853659])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "latter-evidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7472868217054264"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-album",
   "metadata": {},
   "source": [
    "Which is slightly worse than when using only the spacy vectorizer. So the glove vector isn't really doing anything for me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-workplace",
   "metadata": {},
   "source": [
    "## Flair transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "patient-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, DocumentPoolEmbeddings\n",
    "from flair.data import Sentence\n",
    "from hyper.transformers import FlairTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "labeled-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = WordEmbeddings(\"glove\")\n",
    "document_embeddings = DocumentPoolEmbeddings([glove_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "metric-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_transformer = trans.FlairTransformer(document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "textile-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    f_transformer, \n",
    "    LogisticRegression(max_iter=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "following-delicious",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   37.1s remaining:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   41.9s finished\n"
     ]
    }
   ],
   "source": [
    "results = evl.evaluate_algorithm(X, y, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "located-richards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7348837209302326"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-phrase",
   "metadata": {},
   "source": [
    "So compared to the other glove embeddings, these are much better. But they're not quite as good as the spacy embeddings. They're much faster than the spacy embeddings though. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-portugal",
   "metadata": {},
   "source": [
    "### Flair transformer with FlairEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ceramic-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import FlairEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "naked-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_embeddings = FlairEmbeddings(\"news-forward\")\n",
    "pooled_flair_embeddings = DocumentPoolEmbeddings([flair_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "rising-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_transformer = trans.FlairTransformer(pooled_flair_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "smart-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    f_transformer,\n",
    "    LogisticRegression(max_iter=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-financing",
   "metadata": {},
   "source": [
    "This has to train an NN I think so is super slow (I accidentally left it running for hours, didn't finish)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-ethernet",
   "metadata": {},
   "source": [
    "### Flair transformer with TransformerDocumentEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fiscal-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerDocumentEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "romantic-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = TransformerDocumentEmbeddings(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "talented-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FlairTransformer(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conservative-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    transformer,\n",
    "    LogisticRegression(max_iter=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bibliographic-transfer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  accuracy: (test=0.775) f1: (test=0.688) precision: (test=0.711) recall: (test=0.667) total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  accuracy: (test=0.806) f1: (test=0.706) precision: (test=0.811) recall: (test=0.625) total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  accuracy: (test=0.783) f1: (test=0.702) precision: (test=0.717) recall: (test=0.688) total time= 2.3min\n",
      "[CV] END  accuracy: (test=0.837) f1: (test=0.759) precision: (test=0.825) recall: (test=0.702) total time= 2.3min\n",
      "[CV] END  accuracy: (test=0.822) f1: (test=0.763) precision: (test=0.740) recall: (test=0.787) total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.8min finished\n"
     ]
    }
   ],
   "source": [
    "res = evl.evaluate_algorithm(X, y, pipe, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "distributed-jonathan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([112.4225204 , 116.11454725, 109.02963853, 110.20191193,\n",
       "        112.06278419]),\n",
       " 'score_time': array([28.45146108, 32.09502554, 28.80259061, 26.86412263, 24.91251326]),\n",
       " 'test_accuracy': array([0.7751938 , 0.80620155, 0.78294574, 0.8372093 , 0.82170543]),\n",
       " 'test_precision': array([0.71111111, 0.81081081, 0.7173913 , 0.825     , 0.74      ]),\n",
       " 'test_recall': array([0.66666667, 0.625     , 0.6875    , 0.70212766, 0.78723404]),\n",
       " 'test_f1': array([0.68817204, 0.70588235, 0.70212766, 0.75862069, 0.7628866 ])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "resident-oriental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046511627906977"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-audit",
   "metadata": {},
   "source": [
    "This is the most accurate, the issue is, I can't run it in parallel without it blowing up my computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-broadway",
   "metadata": {},
   "source": [
    "## A union of the two best so far\n",
    "Going to do a feature union of the dilbert base uncased sentence level embeddings and the spacy transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dramatic-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = spacy.load(\"en_core_web_md\")\n",
    "spacy_transformer = SpacyTransformer(spacy_model, \"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lyric-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = TransformerDocumentEmbeddings(\"distilbert-base-uncased\")\n",
    "flair_transformer = FlairTransformer(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "global-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_transformer = FeatureUnion(\n",
    "        transformer_list=[\n",
    "            (\"spacy_transformer\", spacy_transformer),\n",
    "            (\"flair_transformer\", flair_transformer),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sudden-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pipeline = make_pipeline(\n",
    "    union_transformer,\n",
    "    LogisticRegression(max_iter=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-holocaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  accuracy: (test=0.814) f1: (test=0.745) precision: (test=0.761) recall: (test=0.729) total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  accuracy: (test=0.767) f1: (test=0.659) precision: (test=0.725) recall: (test=0.604) total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END  accuracy: (test=0.760) f1: (test=0.674) precision: (test=0.681) recall: (test=0.667) total time= 6.2min\n",
      "[CV] END  accuracy: (test=0.853) f1: (test=0.776) precision: (test=0.868) recall: (test=0.702) total time= 5.5min\n"
     ]
    }
   ],
   "source": [
    "log_results = evl.evaluate_algorithm(X, y, log_reg_pipeline, n_jobs=1)\n",
    "print(log_results)\n",
    "print(log_results[\"test_accuracy\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "attached-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7985"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0.814, 0.767, 0.760, 0.853]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-sitting",
   "metadata": {},
   "source": [
    "This keeps crashing but looks like accuracy is going to be something like 0.8\n",
    "\n",
    "That isn't any better than the transfer document embeddings by themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-buffer",
   "metadata": {},
   "source": [
    "### Same but different workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "foreign-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = union_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fatty-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "pleased-perth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.6s remaining:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.8s finished\n"
     ]
    }
   ],
   "source": [
    "resutls = evl.evaluate_algorithm(X_transformed, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "placed-morris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.02787304, 0.98183155, 0.95653915, 1.08852792, 0.88862753]),\n",
       " 'score_time': array([0.00394225, 0.00742865, 0.00881505, 0.00313354, 0.01115441]),\n",
       " 'test_accuracy': array([0.82170543, 0.76744186, 0.75968992, 0.85271318, 0.8372093 ]),\n",
       " 'test_precision': array([0.77777778, 0.725     , 0.68085106, 0.86842105, 0.76      ]),\n",
       " 'test_recall': array([0.72916667, 0.60416667, 0.66666667, 0.70212766, 0.80851064]),\n",
       " 'test_f1': array([0.75268817, 0.65909091, 0.67368421, 0.77647059, 0.78350515])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "compound-royal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8077519379844962"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resutls[\"test_accuracy\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
